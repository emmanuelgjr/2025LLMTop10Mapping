# OWASP Top 10 for Large Language Model Applications 2025 Mapped to ISA/IEC 62443

This repo offers a detailed mapping of the [OWASP Top 10 for LLM Applications 2025](https://genai.owasp.org) to [**ISA/IEC 62443**](https://www.isa.org/standards-and-publications/isa-standards/isa-iec-62443-series-of-standards) standards. This alignment aids developers, risk managers, and security teams in integrating AI-specific vulnerabilities with industrial security practices, aiming for resilient, safe, and regulated AI applications within operational technology (OT) environments.

Each vulnerability includes scenarios, impacts on stakeholders, ethical considerations, recommended tools, implementation guidance, and lifecycle notes tailored to industrial applications.

---

| **Vulnerability**                         | **Risk Level** | **ISA/IEC 62443 Security Requirements**           | **Key Risks**                              | **Top Mitigation Steps**                                |
|-------------------------------------------|----------------|--------------------------------------------------|--------------------------------------------|---------------------------------------------------------|
| LLM01:2025 Prompt Injection               | High           | SR 1.1, SR 1.7, SR 2.6                           | Unauthorized actions, data exposure       | Input validation, prompt integrity enforcement          |
| LLM02:2025 Sensitive Information Disclosure | High          | SR 1.5, SR 3.3, SR 4.2                           | Disclosure of sensitive data               | Data masking, access controls                           |
| LLM03:2025 Supply Chain Vulnerabilities   | Medium         | SR 1.6, SR 2.2, SR 3.8                           | Compromised dependencies                   | Dependency monitoring, supply chain risk assessment     |
| LLM04:2025 Data and Model Poisoning       | High           | SR 2.5, SR 3.2, SR 3.3                           | Compromised data accuracy, model biases    | Data integrity checks, secure data handling             |
| LLM05:2025 Insecure Output Handling       | Medium         | SR 2.2, SR 3.4, SR 4.1                           | Unauthorized output actions                | Output filtering, standardized format requirements      |
| LLM06:2025 Excessive Agency               | Medium         | SR 2.1, SR 2.2, SR 4.2                           | Autonomous risky actions                   | Human approval for high-risk tasks, least privilege     |
| LLM07:2025 System Prompt Leakage          | Medium         | SR 1.7, SR 2.1, SR 4.1                           | Unauthorized prompt exposure               | Secure prompt storage, access restrictions              |
| LLM08:2025 Vector and Embedding Weaknesses | Medium         | SR 2.6, SR 4.3, SR 4.5                           | Malicious or biased outputs                | Bias testing, secure vector storage                     |
| LLM09:2025 Misinformation                 | Medium         | SR 2.4, SR 3.2, SR 4.6                           | Inaccurate or harmful content             | Human oversight, content verification                   |
| LLM10:2025 Unbounded Consumption          | Low            | SR 1.1, SR 2.3, SR 3.9                           | Resource exhaustion                        | Rate limiting, resource monitoring                      |

---

## [LLM01:2025 Prompt Injection](https://genai.owasp.org/)

- **Description**: Attackers manipulate prompt inputs to alter model behaviour, potentially enabling unauthorized actions, disclosing sensitive information, or bypassing safety controls.
  
- **Example Industrial Scenario**: 
  - A maintenance chatbot is manipulated via prompt injection to access unauthorized system configuration data, exposing sensitive operational details.

- **Stakeholder Impact**:
  - **Developers**: Implement secure input validation and prompt structure enforcement.
  - **Compliance Officers**: Maintain strict data handling standards to ensure prompt-based data remains confidential.
  - **Risk Managers**: Monitor prompt integrity as part of risk assessment and management strategies.

- **Ethical Considerations**: 
  - Preventing prompt injection in LLMs within industrial contexts upholds trust, safety, and operational integrity.

- **ISA/IEC 62443 Mapping**:
  - **SR 1.1**: Control and monitor authorized access and interactions with the LLM system.
  - **SR 1.7**: Define and enforce strict policies for input handling at all interaction points.
  - **SR 2.6**: Ensure secure processing for all inputs through validated and controlled mechanisms.

- **Mitigation Strategy Framework**:
  - **Preventive Measures**:
     - Enforce strict input validation frameworks to filter unauthorized prompts.
     - Define clear input and output boundaries to restrict sensitive data responses.
  - **Detective Controls**:
     - Deploy an Intrusion Detection System (IDS) to monitor for abnormal prompt patterns.
     - Use anomaly detection to flag potential prompt injection attempts.
  - **Corrective Actions**:
     - Automatically quarantine or contain outputs flagged as suspicious.
     - Implement containment measures to restrict prompt-based unauthorized access.

- **Implementation Notes by AI Lifecycle**:
  - **Design Stage**: Define authorized prompt formats and restrict ambiguous or open-ended prompts.
  - **Deployment Stage**: Use continuous monitoring tools to check prompt integrity.
  - **Post-Deployment**: Perform regular audits and testing to identify new prompt injection vectors.

- **Risk Assessment and Prioritization**:
  - Prioritize mitigation based on the operational criticality of the LLM function, with higher priority for prompts that control sensitive data or essential functions.

- **Recommended Tools**: OWASP ZAP for testing prompt integrity, regex-based validators for filtering, industrial IDS solutions.

- **Key Risks**: Unauthorized access, data leakage, manipulation of decision-making processes.
  
- **Top Mitigation Steps**: Strict input validation, enforce prompt integrity, continuous monitoring for prompt anomalies.

---

## [LLM02:2025 Sensitive Information Disclosure](https://genai.owasp.org/)

- **Description**: Exposure of sensitive information like PII, proprietary data, or control system configurations due to weak access controls.

- **Example Industrial Scenario**: A control system LLM exposes proprietary algorithms during troubleshooting, risking intellectual property theft.

- **ISA/IEC 62443 Mapping**:
  - **SR 1.5**: Apply data protection measures for all confidential information.
  - **SR 3.3**: Enforce strict access control on sensitive data.
  - **SR 4.2**: Configure data privacy settings to ensure that sensitive data remains protected.

- **Industrial-Specific Mitigation Strategies**:
  - **Preventive Measures**:
    - Integrate data sanitization to prevent sensitive content from entering model outputs.
    - Implement differential privacy techniques to protect individual data points.
  - **Detective Controls**:
    - Conduct regular audits of model outputs for sensitive information.
  - **Corrective Actions**:
    - Apply dynamic data masking when sensitive data is detected in outputs.

- **Stakeholder-Specific Guidance**:
  - **Developers**: Implement masking and access controls for all sensitive fields.
  - **Compliance Officers**: Ensure policies comply with industrial data regulations.
  - **Risk Managers**: Regularly audit LLMs for potential data leakage.

- **Recommended Tools**: TensorFlow Privacy, encryption libraries, privacy-preserving techniques.

- **Key Risks**: Unauthorized access to sensitive data, legal non-compliance.

---

## [LLM03:2025 Supply Chain Vulnerabilities](https://genai.owasp.org/)

- **Description**: Vulnerabilities introduced via unvetted third-party dependencies can impact the integrity of LLM applications.

- **Example Industrial Scenario**: A software dependency used in a critical control LLM has a known vulnerability, leading to unauthorized access.

- **ISA/IEC 62443 Mapping**:
  - **SR 1.6**: Implement risk assessments for third-party components.
  - **SR 2.2**: Require certification and validation for critical dependencies.
  - **SR 3.8**: Monitor supply chain security continuously.

- **Industrial-Specific Mitigation Strategies**:
  - **Preventive Measures**:
    - Enforce regular audits of all dependencies.
    - Require security certifications for critical third-party software.
  - **Detective Controls**:
    - Use software composition analysis tools to identify vulnerabilities.
  - **Corrective Actions**:
    - Quickly isolate and patch any compromised dependencies.

- **Recommended Tools**: OWASP Dependency-Check, Snyk, and Veracode for software composition analysis.

- **Key Risks**: Malicious components, unverified dependencies.

---

## [LLM04:2025 Data and Model Poisoning](https://genai.owasp.org/)

- **Description**: Data poisoning, where malicious data is injected into the LLM’s training data, compromising model accuracy.

- **Example Industrial Scenario**: Poisoned data in a predictive maintenance model leads to incorrect diagnoses, impacting machine uptime.

- **ISA/IEC 62443 Mapping**:
  - **SR 2.5**: Secure all data channels against unauthorized modifications.
  - **SR 3.2**: Implement data integrity protocols.
  - **SR 3.3**: Ensure only authorized modifications to training data.

- **Industrial-Specific Mitigation Strategies**:
  - **Preventive Measures**:
    - Conduct integrity checks on data sources.
  - **Detective Controls**:
    - Regularly monitor data for anomalies that could indicate poisoning.
  - **Corrective Actions**:
    - Revert to previous training datasets if poisoning is detected.

- **Recommended Tools**: Data provenance solutions, anomaly detection systems.

- **Key Risks**: Compromised data integrity, incorrect outputs.

---

## [LLM05:2025 Insecure Output Handling](https://genai.owasp.org/)

- **Description**: Poor handling of output responses can inadvertently disclose sensitive information, execute unintended actions, or allow injection-based attacks (e.g., HTML injection). Outputs must be securely filtered and validated to prevent unauthorized data disclosures or operational impacts.

- **Example Industrial Scenario**: A customer support LLM in a financial setting unintentionally reveals sensitive account details due to improper output filtering, creating privacy risks and possible regulatory violations.

- **Stakeholder Impact**:
  - **Developers**: Need to implement secure encoding, escaping, and filtering for all outputs.
  - **Risk Managers**: Monitor for potential data leakage risks that could impact customer trust and regulatory compliance.
  - **Compliance Officers**: Ensure outputs align with privacy regulations, preventing unauthorized data exposure.

- **Ethical Considerations**: Protecting customer and proprietary information by preventing unauthorized disclosures supports data privacy and fosters user trust.

- **ISA/IEC 62443 Mapping**:
  - **SR 2.2**: Enforce strict output handling to prevent information leakage.
  - **SR 3.4**: Define and implement policies to prevent unauthorized data disclosures.
  - **SR 4.1**: Secure all data output formats to avoid unintentional release of sensitive information.

- **Mitigation Strategy Framework**:
  - **Preventive Measures**:
    - Implement output encoding, escaping, and filtering tools to validate all outputs.
    - Define secure output templates and sanitize outputs to prevent data leakage.
  - **Detective Controls**:
    - Continuously monitor and audit outputs for adherence to security policies.
    - Apply automated scanning tools to detect sensitive data in outputs.
  - **Corrective Actions**:
    - Flag and redact unauthorized disclosures automatically.
    - Regularly update filtering rules based on new data handling policies and threat vectors.

- **Implementation Notes by AI Lifecycle**:
  - **Deployment Stage**: Enforce output filtering and secure formatting protocols.
  - **Post-Deployment**: Continuous monitoring for new injection patterns or output vulnerabilities.

- **Risk Assessment and Prioritization**:
  - Prioritize high-sensitivity data fields to prevent accidental disclosures, especially in high-risk outputs involving PII or financial information.

- **Recommended Tools**: OWASP Encoding Libraries, Secure Formatting Libraries, Data Redaction Tools.

- **Key Risks**: Data leakage, injection vulnerabilities, unauthorized data disclosures.

- **Top Mitigation Steps**: Output filtering, secure formatting, continuous audits.

---

## [LLM06:2025 Excessive Agency](https://genai.owasp.org/)

- **Description**: Excessive agency refers to unintended autonomous actions taken by an LLM, leading to risky or unauthorized decisions. This is particularly relevant in industrial applications where LLMs have the capacity to make high-impact decisions autonomously.

- **Example Industrial Scenario**: An AI-driven maintenance system autonomously schedules repairs on critical machinery without notifying human supervisors, leading to unexpected operational downtime.

- **Stakeholder Impact**:
  - **Developers**: Need to enforce boundaries on LLM autonomy, integrating human oversight for high-risk actions.
  - **Risk Managers**: Monitor and mitigate the risks associated with autonomous decisions to ensure operational safety.
  - **Compliance Officers**: Ensure that autonomous actions adhere to regulatory standards and organizational policies.

- **Ethical Considerations**: Enforcing model boundaries and requiring human oversight prevents unintended harm and supports accountability in automated decision-making.

- **ISA/IEC 62443 Mapping**:
  - **SR 2.1**: Enforce control over AI actions to prevent unapproved agency.
  - **SR 2.2**: Restrict AI actions to defined and authorized roles.
  - **SR 4.2**: Ensure human intervention for high-stakes actions, particularly in safety-critical processes.

- **Mitigation Strategy Framework**:
  - **Preventive Measures**:
    - Enforce the principle of least privilege to limit model permissions.
    - Require human-in-the-loop (HITL) protocols for high-risk decisions.
  - **Detective Controls**:
    - Set up alerts for autonomous actions that exceed predefined thresholds.
    - Conduct regular reviews of LLM logs to identify unauthorized actions.
  - **Corrective Actions**:
    - Immediately halt unapproved autonomous actions.
    - Implement post-incident reviews to adjust model permissions and HITL protocols as needed.

- **Implementation Notes by AI Lifecycle**:
  - **Design Stage**: Define boundaries for AI autonomy and specify HITL requirements.
  - **Deployment Stage**: Monitor for unintended autonomous actions continuously.
  - **Post-Deployment**: Regularly audit autonomy protocols to ensure ongoing alignment with safety standards.

- **Risk Assessment and Prioritization**:
  - Focus on high-stakes applications with potential safety or operational risks, such as LLMs used in industrial control or safety-critical environments.

- **Recommended Tools**: Role-Based Access Control (RBAC) systems, Human Approval Workflow Tools.

- **Key Risks**: Unauthorized decisions, safety risks, unintended model behaviours.

- **Top Mitigation Steps**: Enforce least privilege, human approval, role-based access controls.

---

## [LLM07:2025 System Prompt Leakage](https://genai.owasp.org/)

- **Description**: System prompt leakage occurs when internal prompts that guide the model’s responses are exposed, allowing attackers to manipulate or bypass security controls.

- **Example Industrial Scenario**: An attacker gains access to system prompts in a quality control system, manipulating responses to ignore certain defect criteria.

- **Stakeholder Impact**:
  - **Developers**: Responsible for securing prompt data and implementing access controls.
  - **Risk Managers**: Mitigate risks related to prompt leakage that could compromise operational security.
  - **Compliance Officers**: Ensure the confidentiality of system prompts as part of secure configuration management.

- **Ethical Considerations**: Securing system prompts prevents unauthorized manipulation, supporting reliable and secure interactions in critical systems.

- **ISA/IEC 62443 Mapping**:
  - **SR 1.7**: Protect and restrict access to sensitive system prompts.
  - **SR 2.1**: Implement secure configuration and access controls for all prompt data.
  - **SR 4.1**: Enforce confidentiality and integrity for prompts used in secure configurations.

- **Mitigation Strategy Framework**:
  - **Preventive Measures**:
    - Encrypt and securely store all sensitive system prompts.
    - Restrict access to essential personnel only, following RBAC.
  - **Detective Controls**:
    - Implement access logging and monitor for unauthorized prompt access.
  - **Corrective Actions**:
    - Update prompt configurations in the event of suspected leakage.
    - Implement periodic reviews and re-encryption for prompt data.

- **Implementation Notes by AI Lifecycle**:
  - **Deployment Stage**: Implement secure storage and access control for prompts.
  - **Post-Deployment**: Continuously monitor for unauthorized prompt access or manipulation.

- **Risk Assessment and Prioritization**:
  - Prioritize high-risk systems where prompt manipulation could lead to operational disruption.

- **Recommended Tools**: Secure Configuration Management Tools, Access Management Solutions, Encryption Libraries.

- **Key Risks**: Unauthorized prompt access, model manipulation.

- **Top Mitigation Steps**: Secure prompt storage, access control, policy compliance checks.

---

## [LLM08:2025 Vector and Embedding Weaknesses](https://genai.owasp.org/)

- **Description**: Weaknesses in data embeddings and vectors can lead to biased, manipulated, or adversarially altered outputs, affecting the model’s reliability and fairness.

- **Example Industrial Scenario**: Bias in embeddings used in a job-matching LLM causes it to favour certain demographic groups unfairly, leading to potential reputational damage and regulatory scrutiny.

- **Stakeholder Impact**:
  - **Developers**: Implement techniques for bias detection and secure embedding management.
  - **Risk Managers**: Assess potential biases in embeddings to prevent reputational and operational risks.
  - **Compliance Officers**: Validate model outputs for fairness, especially in regulated or compliance-focused environments.

- **Ethical Considerations**: Ensuring fairness in embeddings promotes equitable outcomes and upholds ethical AI principles.

- **ISA/IEC 62443 Mapping**:
  - **SR 2.6**: Apply secure processing to vectors and embeddings to prevent manipulation.
  - **SR 4.3**: Validate model embeddings to ensure unbiased and fair outcomes.
  - **SR 4.5**: Monitor vectors and embeddings for integrity to prevent adversarial manipulation.

- **Mitigation Strategy Framework**:
  - **Preventive Measures**:
    - Conduct adversarial testing to detect vulnerabilities in embeddings.
    - Apply bias detection tools to evaluate and mitigate potential biases in embeddings.
  - **Detective Controls**:
    - Monitor embeddings for unusual or manipulated patterns.
  - **Corrective Actions**:
    - Retrain or reconfigure embeddings if biases or vulnerabilities are detected.

- **Implementation Notes by AI Lifecycle**:
  - **Training Stage**: Conduct robust bias detection and mitigation for embeddings.
  - **Deployment Stage**: Ensure continuous monitoring to detect any emerging biases.

- **Risk Assessment and Prioritization**:
  - Focus on embeddings used in decision-making contexts with high regulatory scrutiny, such as hiring or finance.

- **Recommended Tools**: Fairlearn, Microsoft InterpretML, Secure Storage Solutions for Vectors.

- **Key Risks**: Biased outputs, model manipulation, reduced trustworthiness.

- **Top Mitigation Steps**: Adversarial testing, secure vector storage, bias detection.

---

## [LLM09:2025 Misinformation](https://genai.owasp.org/)

- **Description**: Misinformation occurs when an LLM generates inaccurate or misleading information, which can lead to user trust issues, especially in critical applications such as healthcare or finance.

- **Example Industrial Scenario**: A healthcare chatbot used by medical staff provides incorrect advice due to misinformation, potentially endangering patient safety.

- **Stakeholder Impact**:
  - **Developers**: Responsible for implementing verification mechanisms for high-stakes outputs.
  - **Risk Managers**: Monitor outputs for accuracy to mitigate misinformation risks.
  - **Compliance Officers**: Ensure that outputs adhere to accuracy standards, particularly in regulated industries.

- **Ethical Considerations**: Delivering accurate information supports user safety and trust, especially in environments where misinformation could result in harm.

- **ISA/IEC 62443 Mapping**:
  - **SR 2.4**: Enforce quality control standards for accurate and reliable outputs.
  - **SR 3.2**: Apply accuracy standards for data, especially in high-stakes settings.
  - **SR 4.6**: Implement continuous verification to prevent the spread of misinformation.

- **Mitigation Strategy Framework**:
  - **Preventive Measures**:
    - Integrate cross-verification with trusted sources for high-risk outputs.
    - Implement retrieval-augmented generation (RAG) to improve output reliability.
  - **Detective Controls**:
    - Continuously monitor outputs and validate accuracy.
  - **Corrective Actions**:
    - Enable feedback mechanisms to adjust and correct misinformation in real-time.

- **Implementation Notes by AI Lifecycle**:
  - **Training Stage**: Emphasize high-quality training data to ensure reliable outputs.
  - **Post-Deployment**: Set up monitoring for real-time validation of high-stakes outputs.

- **Risk Assessment and Prioritization**:
  - Prioritize outputs used in critical decision-making contexts, such as healthcare, finance, or industrial safety applications.

- **Recommended Tools**: Cross-Verification Tools, Retrieval-Augmented Generation (RAG) Techniques.

- **Key Risks**: Inaccurate information, erosion of user trust, regulatory non-compliance.

- **Top Mitigation Steps**: Cross-verification, human oversight, factual consistency checks.

---

## [LLM10:2025 Unbounded Consumption](https://genai.owasp.org/)

- **Description**: Unbounded consumption refers to excessive resource usage by LLMs, potentially leading to denial of service (DoS) or degraded performance. Effective resource management is essential for scalable and reliable operations in industrial environments.

- **Example Industrial Scenario**: A production line monitoring system uses an LLM that consumes excessive resources during peak hours, resulting in system slowdowns and decreased productivity.

- **Stakeholder Impact**:
  - **Developers**: Implement resource usage limits and efficient processing.
  - **Risk Managers**: Focus on maintaining system availability and preventing DoS incidents.
  - **Compliance Officers**: Ensure service reliability aligns with SLAs, especially in critical industrial applications.

- **Ethical Considerations**: Efficient resource management supports continuous service delivery, benefiting users and maintaining trust.

- **ISA/IEC 62443 Mapping**:
  - **SR 1.1**: Define and enforce service boundaries to manage rate limits.
  - **SR 2.3**: Apply monitoring for resource usage to prevent DoS.
  - **SR 3.9**: Continuously assess system load and enforce resource consumption limits.

- **Mitigation Strategy Framework**:
  - **Preventive Measures**:
    - Enforce rate limiting and load balancing for resource-intensive tasks.
    - Use resource allocation policies to optimize usage during peak times.
  - **Detective Controls**:
    - Monitor resource usage in real-time to detect sudden spikes.
  - **Corrective Actions**:
    - Dynamically adjust resource limits during high-demand periods to maintain performance.

- **Implementation Notes by AI Lifecycle**:
  - **Deployment Stage**: Implement resource usage monitoring and rate-limiting mechanisms.
  - **Post-Deployment**: Continuously monitor for anomalies in resource consumption.

- **Risk Assessment and Prioritization**:
  - Prioritize applications with high resource usage or where service continuity is critical, such as production line management systems.

- **Recommended Tools**: Rate Limiting Tools (e.g., Kong), Load Balancing Solutions, Resource Monitoring Tools (e.g., Prometheus).

- **Key Risks**: Denial of service, resource exhaustion, degraded performance.

- **Top Mitigation Steps**: Rate-limiting, load balancing, resource monitoring.


---

### Risk Matrix for Prioritization

| **Vulnerability**      | **Likelihood** | **Impact** | **Priority** |
|------------------------|----------------|------------|--------------|
| Prompt Injection       | High           | High       | High         |
| Sensitive Information Disclosure | Medium  | High      | High         |

---

**Next Steps**:
- Implement and prioritize mitigation strategies based on risk level.
- Set up continuous monitoring for compliance with ISA/IEC 62443.
  
**Further Reading**:
- [ISA/IEC 62443 Standards](https://www.isa.org/standards-and-publications/isa-standards/isa-iec-62443-series)
- [OWASP Top 10 for LLM Applications](https://genai.owasp.org)
