# OWASP Top 10 for LLM Applications Mapped to ISO/IEC 20547-4:2020

This repo provides a comprehensive mapping of the vulnerabilities identified in the [**OWASP Top 10 for Large Language Model Applications: 2025**](https://genai.owasp.org/) to the relevant aspects of [**ISO/IEC 20547-4:2020**](https://www.iso.org/standard/73982.html), which addresses "Big Data Reference Architecture - Security and Privacy." The aim is to enhance the security posture of LLM applications while ensuring compliance with international standards.

## Table of Contents
1. [LLM01:2025 Prompt Injection](https://genai.owasp.org/)
2. [LLM02:2025 Sensitive Information Disclosure](https://genai.owasp.org/)
3. [LLM03:2025 Supply Chain Risks](https://genai.owasp.org/)
4. [LLM04:2025 Data and Model Poisoning](https://genai.owasp.org/)
5. [LLM05:2025 Insecure Output Handling](https://genai.owasp.org/)
6. [LLM06:2025 Excessive Agency](https://genai.owasp.org/)
7. [LLM07:2025 System Prompt Leakage](https://genai.owasp.org/)
8. [LLM08:2025 Vector and Embedding Weaknesses](https://genai.owasp.org/)
9. [LLM09:2025 Misinformation](https://genai.owasp.org/)
10. [LLM10:2025 Unbounded Consumption](https://genai.owasp.org/)

---

### LLM01:2025 Prompt Injection

- **Description**: Prompt Injection occurs when user inputs alter the modelâ€™s behaviour unexpectedly, leading to unauthorized access, sensitive data exposure, or malicious decision-making.
- **ISO/IEC 20547-4:2020 Mapping**:
  - **Security Mechanisms (Clause 5.2)**: Enforces robust access control and data integrity mechanisms to ensure prompts cannot be maliciously manipulated.
  - **Privacy Protection (Clause 5.3)**: Emphasizes privacy-preserving techniques to safeguard sensitive information when dealing with prompts.
- **Best Practices**:
  - Implement input validation and sanitization to prevent manipulation.
  - Establish a feedback loop for monitoring and mitigating instances of prompt injection.
- **Real-World Scenario**: Imagine an LLM integrated with a financial chatbot. If a user manipulates the input prompt to bypass account verifications, it could lead to unauthorized access and data leakage. Using ISO standards, access control mechanisms would restrict such actions.

### LLM02:2025 Sensitive Information Disclosure

- **Description**: LLMs can inadvertently disclose sensitive data, such as personally identifiable information (PII) or proprietary algorithms.
- **ISO/IEC 20547-4:2020 Mapping**:
  - **Data Protection (Clause 5.3.3)**: Enforces strict data protection protocols to prevent sensitive information exposure.
  - **Access Control (Clause 5.2.2)**: Implements access control models to restrict access to sensitive data.
- **Best Practices**:
  - Apply differential privacy techniques to minimize the risk of sensitive data exposure.
  - Use redaction and entity recognition tools to detect and sanitize sensitive information.

### LLM03:2025 Supply Chain Risks

- **Description**: Risks associated with third-party integrations, dependencies, and data pipelines that can compromise model integrity.
- **ISO/IEC 20547-4:2020 Mapping**:
  - **Supply Chain Security (Clause 6.2.1)**: Recommends secure sourcing, validation, and verification of data and components used in LLMs.
  - **Data Quality Management (Clause 6.1.3)**: Ensures data reliability and integrity throughout the supply chain.
- **Best Practices**:
  - Conduct regular audits of third-party integrations and dependencies.
  - Ensure data suppliers adhere to security and privacy standards.

### LLM04:2025 Data and Model Poisoning

- **Description**: Manipulation of data or models to produce biased or incorrect outcomes.
- **ISO/IEC 20547-4:2020 Mapping**:
  - **Data Integrity (Clause 5.3.5)**: Emphasizes mechanisms to detect and prevent data corruption and manipulation.
  - **Model Validation (Clause 6.3.1)**: Recommends rigorous model testing and validation techniques.
- **Best Practices**:
  - Employ anomaly detection to identify poisoned data.
  - Use multi-stage model validation to prevent poisoned models from being deployed.

### LLM05:2025 Insecure Output Handling

- **Description**: Poor handling of model outputs, potentially leading to code injection, content manipulation, or sensitive data leaks.
- **ISO/IEC 20547-4:2020 Mapping**:
  - **Output Sanitization (Clause 5.2.5)**: Recommends sanitization and validation of outputs to prevent injection attacks.
  - **Error Management (Clause 6.4.2)**: Ensures error handling does not expose sensitive information.
- **Best Practices**:
  - Sanitize model outputs before displaying them to users.
  - Implement secure coding practices for output management.

### LLM06:2025 Excessive Agency

- **Description**: Occurs when LLMs have too much autonomy, potentially performing unauthorized actions.
- **ISO/IEC 20547-4:2020 Mapping**:
  - **Operational Controls (Clause 5.4.1)**: Defines control mechanisms to limit LLM autonomy.
  - **Risk Management (Clause 6.5.1)**: Calls for risk assessment processes to evaluate LLM capabilities and permissions.
- **Best Practices**:
  - Limit the actions that LLMs can autonomously perform.
  - Implement approval workflows for high-risk LLM activities.

### LLM07:2025 System Prompt Leakage

- **Description**: Leakage of internal system prompts that can expose sensitive information or system configurations.
- **ISO/IEC 20547-4:2020 Mapping**:
  - **Confidentiality (Clause 5.2.1)**: Emphasizes the protection of internal prompts and system details.
  - **Audit Controls (Clause 6.2.3)**: Supports regular audits to prevent unintended leakage.
- **Best Practices**:
  - Mask internal prompts before providing responses to users.
  - Perform regular audits to identify and mitigate prompt leakage risks.

### LLM08:2025 Vector and Embedding Weaknesses

- **Description**: Weaknesses in embeddings or vector representations that could be exploited to alter outputs or disclose data.
- **ISO/IEC 20547-4:2020 Mapping**:
  - **Data Transformation Controls (Clause 6.3.5)**: Ensures secure handling of data transformations and embeddings.
  - **Model Protection (Clause 5.5.2)**: Recommends robust protection mechanisms for embeddings to prevent exploitation.
- **Best Practices**:
  - Apply encryption techniques to protect embedding vectors.
  - Use regular monitoring to detect anomalies in vector representations.

### LLM09:2025 Misinformation

- **Description**: Generation or dissemination of incorrect or misleading information.
- **ISO/IEC 20547-4:2020 Mapping**:
  - **Data Accuracy (Clause 6.1.1)**: Promotes accurate data representation and processing.
  - **Content Validation (Clause 5.3.7)**: Emphasizes the importance of content validation to prevent misinformation.
- **Best Practices**:
  - Implement content verification mechanisms to detect misinformation.
  - Regularly update training data to include verified and reliable sources.

### LLM10:2025 Unbounded Consumption

- **Description**: Uncontrolled resource consumption that can lead to denial of service or resource exhaustion.
- **ISO/IEC 20547-4:2020 Mapping**:
  - **Resource Management (Clause 5.2.7)**: Recommends mechanisms to manage and limit resource usage.
  - **Scalability Controls (Clause 6.4.5)**: Ensures systems can scale appropriately without compromising availability.
- **Best Practices**:
  - Use rate limiting and throttling mechanisms to control resource consumption.
  - Monitor system usage to detect and respond to potential resource exhaustion.

---

This mapping helps align LLM security and privacy practices with international standards, providing organizations with a structured approach to managing risks associated with LLMs. ISO/IEC 20547-4:2020 guidelines implemented in organizations can enhance trust, safety, and compliance when deploying LLM-based applications.

### References
- [ISO/IEC 20547-4:2020 Security and Privacy](https://www.iso.org/standard/73982.html)
