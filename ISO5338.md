# OWASP Top 10 for Large Language Model Applications 2025 Mapped to ISO/IEC 5338

This repo provides a detailed mapping of the vulnerabilities outlined in the [OWASP Top 10 for LLM Applications: 2025](https://genai.owasp.org) to **ISO/IEC 5338** standards. This guide helps developers and security teams integrate AI-specific security practices into established ISO/IEC 5338 security guidelines.

| **Vulnerability**                         | **Risk Level** | **ISO/IEC 5338 Sections**                             | **Key Risks**                              | **Top Mitigation Steps**                                |
|-------------------------------------------|------------|--------------------------------------------------|----------------------------------------|-----------------------------------------------------|
| LLM01:2025 Prompt Injection               | High       | Input Data Integrity, User Authentication              | Unauthorized access, data leakage      | Strict input validation, enforce prompt integrity    |
| LLM02:2025 Sensitive Information Disclosure | High       | Data Confidentiality, Access Control Policies         | Exposure of sensitive information      | Data masking, access controls                       |
| LLM03:2025 Supply Chain Vulnerabilities   | Medium     | Third-Party Risk Management, Secure Integration       | Malicious components, unverified dependencies | Regular audits, use of dependency monitoring tools   |
| LLM04:2025 Data and Model Poisoning       | High       | Data Integrity, AI System Security                    | Compromised training data, incorrect outputs | Data audits, secure data pipelines                  |
| LLM05:2025 Insecure Output Handling       | Medium     | Output Filtering, Secure Content Processing           | Data leakage, injection vulnerabilities | Output filtering, output format definitions         |
| LLM06:2025 Excessive Agency               | Medium     | Privilege Management, Automated Process Monitoring    | Unintended autonomous actions          | Enforce least privilege, human approval for high-risk actions |
| LLM07:2025 System Prompt Leakage          | Medium     | Information Disclosure Controls, System Configuration  | System prompt exposure                 | Conceal system prompts, implement secure configurations |
| LLM08:2025 Vector and Embedding Weaknesses | Medium     | Data Validation, AI Security                          | Biased or malicious outputs            | Adversarial testing, secure vector storage          |
| LLM09:2025 Misinformation                 | Medium     | Data Accuracy, Model Performance Assessment           | Inaccurate or misleading content      | Cross-verification, human oversight                  |
| LLM10:2025 Unbounded Consumption          | Low        | Resource Allocation, Denial of Service Protections    | Excessive resource usage, denial of service | Rate-limiting, load balancing                       |

---

## [LLM01:2025 Prompt Injection](https://genai.owasp.org/)

- **Description**: Prompt injection occurs when user inputs alter the behavior of the LLM, potentially causing unauthorized access or manipulation.

- **ISO/IEC 5338 Mapping**:
  - **ISO/IEC 5338: 4.2.1 Input Data Integrity**: Ensure inputs to LLMs are validated to prevent manipulation.
  - **ISO/IEC 5338: 4.3.5 User Authentication**: Restrict prompt injections that may allow unauthorized actions.

- **Mitigation Strategies**:
  1. Constrain model behavior using defined roles.
  2. Validate output formats using deterministic code.

- **Key Risks**: Unauthorized access, data leakage
- **Top Mitigation Steps**: Strict input validation, enforce prompt integrity

---

## [LLM02:2025 Sensitive Information Disclosure](https://genai.owasp.org/)

- **Description**: LLMs risk exposing sensitive data, including PII and proprietary information.

- **ISO/IEC 5338 Mapping**:
  - **ISO/IEC 5338: 4.5.2 Data Confidentiality**: Implement data masking and sanitization to protect sensitive information.
  - **ISO/IEC 5338: 4.6.1 Access Control Policies**: Enforce access controls to prevent unauthorized data access.

- **Mitigation Strategies**:
  1. Apply data sanitization.
  2. Use federated learning and differential privacy.

- **Key Risks**: Exposure of sensitive information
- **Top Mitigation Steps**: Data masking, access controls

---

## [LLM03:2025 Supply Chain Vulnerabilities](https://genai.owasp.org/)

- **Description**: Supply chain vulnerabilities can lead to security issues in LLM deployments.

- **ISO/IEC 5338 Mapping**:
  - **ISO/IEC 5338: 5.4.3 Third-Party Risk Management**: Ensure secure integration of external components.
  - **ISO/IEC 5338: 5.6.5 Secure Integration**: Regularly audit dependencies to mitigate supply chain risks.

- **Mitigation Strategies**:
  1. Conduct regular audits of third-party components.
  2. Use dependency monitoring tools.

- **Key Risks**: Malicious components, unverified dependencies
- **Top Mitigation Steps**: Regular audits, dependency monitoring tools

---

## [LLM04:2025 Data and Model Poisoning](https://genai.owasp.org/)

- **Description**: Data poisoning occurs when malicious inputs compromise training data, resulting in harmful outputs.

- **ISO/IEC 5338 Mapping**:
  - **ISO/IEC 5338: 6.2.1 Data Integrity**: Ensure that training data is validated to prevent poisoning.
  - **ISO/IEC 5338: 7.3.5 AI System Security**: Implement safeguards to maintain model integrity.

- **Mitigation Strategies**:
  1. Conduct regular data audits to detect anomalies.
  2. Implement secure, encrypted data pipelines.

- **Key Risks**: Compromised training data, incorrect outputs
- **Top Mitigation Steps**: Data audits, secure data pipelines

---

## [LLM05:2025 Insecure Output Handling](https://genai.owasp.org/)

- **Description**: LLMs can produce outputs that inadvertently disclose sensitive information or trigger unintended actions.

- **ISO/IEC 5338 Mapping**:
  - **ISO/IEC 5338: 5.3.2 Output Filtering**: Apply filtering to control and sanitize outputs.
  - **ISO/IEC 5338: 5.6.4 Secure Content Processing**: Validate all outputs to prevent data leakage or command injection.

- **Mitigation Strategies**:
  1. Implement output filtering and validation mechanisms.
  2. Define strict output formats to prevent harmful data leakage.

- **Key Risks**: Data leakage, injection vulnerabilities
- **Top Mitigation Steps**: Output filtering, output format definitions

---

## [LLM06:2025 Excessive Agency](https://genai.owasp.org/)

- **Description**: Excessive agency refers to unintended autonomous actions by the LLM, such as making unauthorized decisions.

- **ISO/IEC 5338 Mapping**:
  - **ISO/IEC 5338: 4.4.5 Privilege Management**: Limit model permissions to essential functions.
  - **ISO/IEC 5338: 7.2.3 Automated Process Monitoring**: Monitor automated actions and implement human-in-the-loop controls.

- **Mitigation Strategies**:
  1. Enforce least privilege principles.
  2. Require human approval for high-risk actions.

- **Key Risks**: Unintended autonomous actions
- **Top Mitigation Steps**: Enforce least privilege, human approval for high-risk actions

---

## [LLM07:2025 System Prompt Leakage](https://genai.owasp.org/)

- **Description**: System prompts can be exposed, allowing unauthorized manipulation of model behavior.

- **ISO/IEC 5338 Mapping**:
  - **ISO/IEC 5338: 5.3.1 Information Disclosure Controls**: Prevent unauthorized access to system prompts.
  - **ISO/IEC 5338: 5.5.3 System Configuration Management**: Securely configure prompts and settings to reduce exposure risks.

- **Mitigation Strategies**:
  1. Conceal system prompts and use secure storage solutions.
  2. Implement robust configuration practices.

- **Key Risks**: System prompt exposure
- **Top Mitigation Steps**: Conceal system prompts, implement secure configuration practices

---

## [LLM08:2025 Vector and Embedding Weaknesses](https://genai.owasp.org/)

- **Description**: Vulnerabilities in embeddings can lead to biased or manipulated outputs.

- **ISO/IEC 5338 Mapping**:
  - **ISO/IEC 5338: 6.2.3 Data Validation**: Validate embeddings to mitigate adversarial attacks.
  - **ISO/IEC 5338: 7.4.2 AI Security Measures**: Implement security measures for vector and embedding storage.

- **Mitigation Strategies**:
  1. Conduct adversarial testing on embeddings.
  2. Use secure vector databases.

- **Key Risks**: Biased or malicious outputs
- **Top Mitigation Steps**: Adversarial testing, secure vector databases

---

## [LLM09:2025 Misinformation](https://genai.owasp.org/)

- **Description**: Misinformation occurs when LLMs generate inaccurate or misleading content.

- **ISO/IEC 5338 Mapping**:
  - **ISO/IEC 5338: 6.1.5 Data Accuracy**: Ensure that data is accurate to reduce misinformation.
  - **ISO/IEC 5338: 7.3.2 Model Performance Assessment**: Regularly validate model performance to prevent misinformation.

- **Mitigation Strategies**:
  1. Implement cross-verification and human oversight.
  2. Use retrieval-augmented generation techniques for accuracy.

- **Key Risks**: Inaccurate or misleading content
- **Top Mitigation Steps**: Cross-verification, human oversight

---

## [LLM10:2025 Unbounded Consumption](https://genai.owasp.org/)

- **Description**: Unbounded resource consumption by LLMs can lead to potential denial-of-service (DoS) issues.

- **ISO/IEC 5338 Mapping**:
  - **ISO/IEC 5338: 5.4.6 Resource Allocation and Management**: Manage and monitor resource usage to prevent overconsumption.
  - **ISO/IEC 5338: 5.7.1 Denial of Service Protections**: Implement DoS protections to mitigate excessive resource consumption.

- **Mitigation Strategies**:
  1. Apply rate-limiting and load balancing.
  2. Monitor AI workloads to prevent resource exhaustion.

- **Key Risks**: Excessive resource usage, denial of service
- **Top Mitigation Steps**: Rate-limiting, load balancing

---

This mapping provides a structured approach to incorporating AI security controls within ISO/IEC 5338, facilitating the secure deployment of LLMs.

**Next Steps**:
- Evaluate and prioritize vulnerabilities based on risk level.
- Conduct regular audits and use automated tools to ensure compliance with ISO/IEC 5338 standards.
- Engage with AI security communities to stay updated with best practices.

**Further Reading**:
- [ISO/IEC 5338 Security Standards](https://www.iso.org)
- [OWASP Top 10 for LLM Applications](https://genai.owasp.org)


