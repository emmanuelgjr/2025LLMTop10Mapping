# OWASP Top 10 for Large Language Model Applications 2025 Mapped to ISO/IEC 22989

This repo provides a detailed mapping of the vulnerabilities outlined in the [OWASP Top 10 for LLM Applications: 2025](https://genai.owasp.org) to [**ISO/IEC 22989**](https://www.iso.org/standard/74296.html) standards. This mapping assists developers and security teams in aligning AI-specific security practices with ISO/IEC 22989, focusing on AI concepts and terminology, including trustworthiness, robustness, and data quality.

| **Vulnerability**                         | **Risk Level** | **ISO/IEC 22989 Sections**                             | **Key Risks**                              | **Top Mitigation Steps**                                |
|-------------------------------------------|------------|--------------------------------------------------|----------------------------------------|-----------------------------------------------------|
| LLM01:2025 Prompt Injection               | High       | Input Control, Mitigation of Manipulative Inputs       | Unauthorized access, data leakage      | Strict input validation, enforce prompt integrity    |
| LLM02:2025 Sensitive Information Disclosure | High       | Data Confidentiality, Data Handling Transparency      | Exposure of sensitive information      | Data masking, access controls                       |
| LLM03:2025 Supply Chain Vulnerabilities   | Medium     | Trust in Supply Chain Components, Verification of Dependencies | Malicious components, unverified dependencies | Regular audits, use of dependency monitoring tools   |
| LLM04:2025 Data and Model Poisoning       | High       | Data Quality, Integrity of Training Data               | Compromised training data, incorrect outputs | Data audits, secure data pipelines                  |
| LLM05:2025 Insecure Output Handling       | Medium     | Output Management, Prevention of Sensitive Data Exposure | Data leakage, injection vulnerabilities | Output filtering, output format definitions         |
| LLM06:2025 Excessive Agency               | Medium     | Control of Autonomous Actions, AI System Boundaries   | Unintended autonomous actions          | Enforce least privilege, human approval for high-risk actions |
| LLM07:2025 System Prompt Leakage          | Medium     | Protection of System Prompts, Data Confidentiality    | System prompt exposure                 | Conceal system prompts, implement secure configurations |
| LLM08:2025 Vector and Embedding Weaknesses | Medium     | Data Robustness, Security of AI Embeddings            | Biased or malicious outputs            | Adversarial testing, secure vector storage          |
| LLM09:2025 Misinformation                 | Medium     | Trustworthiness of AI Outputs, Data Accuracy          | Inaccurate or misleading content      | Cross-verification, human oversight                  |
| LLM10:2025 Unbounded Consumption          | Low        | Resource Efficiency, AI System Performance Management | Excessive resource usage, denial of service | Rate-limiting, load balancing                       |

---

## [LLM01:2025 Prompt Injection](https://genai.owasp.org/)

- **Description**: Prompt injection occurs when user inputs alter the behavior of the LLM, potentially causing unauthorized access or manipulation.

- **ISO/IEC 22989 Mapping**:
  - **ISO/IEC 22989: 4.2 Input Control**: Ensure inputs are securely handled to prevent manipulative prompts.
  - **ISO/IEC 22989: 5.3 Mitigation of Manipulative Inputs**: Implement measures to prevent unauthorized access through prompts.

- **Mitigation Strategies**:
  1. Constrain model behavior with strict input validation.
  2. Validate expected output formats to prevent manipulation.

- **Key Risks**: Unauthorized access, data leakage
- **Top Mitigation Steps**: Strict input validation, enforce prompt integrity

---

## [LLM02:2025 Sensitive Information Disclosure](https://genai.owasp.org/)

- **Description**: LLMs may inadvertently expose sensitive data, including personal information or proprietary content.

- **ISO/IEC 22989 Mapping**:
  - **ISO/IEC 22989: 5.4 Data Confidentiality**: Protect sensitive data and ensure confidentiality during processing.
  - **ISO/IEC 22989: 6.1 Data Handling Transparency**: Make data handling practices transparent to maintain trust.

- **Mitigation Strategies**:
  1. Apply data masking and sanitization.
  2. Use access controls to prevent data exposure.

- **Key Risks**: Exposure of sensitive information
- **Top Mitigation Steps**: Data masking, access controls

---

## [LLM03:2025 Supply Chain Vulnerabilities](https://genai.owasp.org/)

- **Description**: Vulnerabilities in the AI supply chain can lead to security risks in LLM implementations.

- **ISO/IEC 22989 Mapping**:
  - **ISO/IEC 22989: 7.3 Trust in Supply Chain Components**: Evaluate third-party components for trustworthiness.
  - **ISO/IEC 22989: 5.6 Verification of Dependencies**: Regularly verify dependencies to ensure their integrity.

- **Mitigation Strategies**:
  1. Conduct regular audits of third-party components.
  2. Use monitoring tools for security compliance.

- **Key Risks**: Malicious components, unverified dependencies
- **Top Mitigation Steps**: Regular audits, dependency monitoring tools

---

## [LLM04:2025 Data and Model Poisoning](https://genai.owasp.org/)

- **Description**: Data poisoning occurs when malicious inputs compromise training data, affecting the model's performance and outputs.

- **ISO/IEC 22989 Mapping**:
  - **ISO/IEC 22989: 6.2 Data Quality**: Ensure quality and consistency of training data to avoid poisoning.
  - **ISO/IEC 22989: 5.8 Integrity of Training Data**: Implement protections to maintain training data integrity.

- **Mitigation Strategies**:
  1. Conduct regular data audits to detect anomalies.
  2. Use secure data pipelines for training environments.

- **Key Risks**: Compromised training data, incorrect outputs
- **Top Mitigation Steps**: Data audits, secure data pipelines

---

## [LLM05:2025 Insecure Output Handling](https://genai.owasp.org/)

- **Description**: LLMs may produce outputs that disclose sensitive information or perform unintended actions.

- **ISO/IEC 22989 Mapping**:
  - **ISO/IEC 22989: 5.7 Output Management**: Manage outputs to prevent data leakage or unauthorized actions.
  - **ISO/IEC 22989: 6.6 Prevention of Sensitive Data Exposure**: Secure outputs to prevent accidental data exposure.

- **Mitigation Strategies**:
  1. Implement output filtering and validation.
  2. Define strict output formats to protect against data leakage.

- **Key Risks**: Data leakage, injection vulnerabilities
- **Top Mitigation Steps**: Output filtering, output format definitions

---

## [LLM06:2025 Excessive Agency](https://genai.owasp.org/)

- **Description**: Excessive agency refers to unintended autonomous actions by LLMs, such as making unauthorized decisions.

- **ISO/IEC 22989 Mapping**:
  - **ISO/IEC 22989: 6.8 Control of Autonomous Actions**: Limit AI autonomy to ensure controlled actions.
  - **ISO/IEC 22989: 5.9 AI System Boundaries**: Define boundaries to manage the scope of autonomous actions.

- **Mitigation Strategies**:
  1. Enforce privilege control and limit autonomy.
  2. Require human approval for high-risk actions.

- **Key Risks**: Unintended autonomous actions
- **Top Mitigation Steps**: Enforce least privilege, human approval for high-risk actions

---

## [LLM07:2025 System Prompt Leakage](https://genai.owasp.org/)

- **Description**: Exposure of system prompts can enable unauthorized users to manipulate model behavior.

- **ISO/IEC 22989 Mapping**:
  - **ISO/IEC 22989: 5.5 Protection of System Prompts**: Ensure prompts are securely managed and stored.
  - **ISO/IEC 22989: 6.4 Data Confidentiality**: Protect system prompts to prevent leakage and unauthorized access.

- **Mitigation Strategies**:
  1. Conceal system prompts and store them securely.
  2. Use secure configuration practices.

- **Key Risks**: System prompt exposure
- **Top Mitigation Steps**: Conceal system prompts, secure configurations

---

## [LLM08:2025 Vector and Embedding Weaknesses](https://genai.owasp.org/)

- **Description**: Weaknesses in embeddings can lead to biased or manipulated outputs.

- **ISO/IEC 22989 Mapping**:
  - **ISO/IEC 22989: 6.7 Data Robustness**: Ensure robustness of embeddings to prevent adversarial manipulation.
  - **ISO/IEC 22989: 5.2 Security of AI Embeddings**: Secure embeddings to protect against biases and manipulation.

- **Mitigation Strategies**:
  1. Conduct adversarial testing on embeddings.
  2. Use secure storage for vector data.

- **Key Risks**: Biased or malicious outputs
- **Top Mitigation Steps**: Adversarial testing, secure vector storage

---

## [LLM09:2025 Misinformation](https://genai.owasp.org/)

- **Description**: LLMs may generate inaccurate or misleading content, affecting data reliability and user trust.

- **ISO/IEC 22989 Mapping**:
  - **ISO/IEC 22989: 5.1 Trustworthiness of AI Outputs**: Ensure that AI-generated outputs are reliable and accurate.
  - **ISO/IEC 22989: 6.9 Data Accuracy**: Regularly validate model outputs to maintain trust.

- **Mitigation Strategies**:
  1. Apply cross-verification and human oversight.
  2. Use retrieval-augmented generation for improved accuracy.

- **Key Risks**: Inaccurate or misleading content
- **Top Mitigation Steps**: Cross-verification, human oversight

---

## [LLM10:2025 Unbounded Consumption](https://genai.owasp.org/)

- **Description**: Unbounded resource consumption by LLMs can lead to performance issues, including denial-of-service (DoS).

- **ISO/IEC 22989 Mapping**:
  - **ISO/IEC 22989: 6.3 Resource Efficiency**: Control and manage resource allocation to prevent overconsumption.
  - **ISO/IEC 22989: 5.10 AI System Performance Management**: Implement protections to manage system resources effectively.

- **Mitigation Strategies**:
  1. Apply rate-limiting and load balancing.
  2. Monitor AI workloads to prevent service disruptions.

- **Key Risks**: Excessive resource usage, denial of service
- **Top Mitigation Steps**: Rate-limiting, load balancing

---

This mapping supports AI security and robustness by aligning with ISO/IEC 22989 standards for trustworthiness, robustness, and data quality in LLM applications.

**Next Steps**:
- Implement prioritized mitigation strategies based on risk levels.
- Regularly monitor compliance with ISO/IEC 22989 using automated tools.
- Stay informed on best practices and updates in AI robustness.

**Further Reading**:
- [ISO/IEC 22989 AI Concepts and Terminology](https://www.iso.org)
- [OWASP Top 10 for LLM Applications](https://genai.owasp.org)
