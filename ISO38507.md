# OWASP Top 10 for Large Language Model Applications 2025 Mapped to ISO/IEC 38507

This repo provides a detailed mapping of the vulnerabilities outlined in the [OWASP Top 10 for LLM Applications: 2025](https://genai.owasp.org) to [**ISO/IEC 38507**](https://www.iso.org/standard/56641.html) guidelines for AI governance. This mapping aids developers and governance teams in aligning AI-specific security risks with strategic oversight and risk management standards.

| **Vulnerability**                         | **Risk Level** | **ISO/IEC 38507 Principles**                          | **Key Risks**                              | **Top Mitigation Steps**                                |
|-------------------------------------------|------------|--------------------------------------------------|----------------------------------------|-----------------------------------------------------|
| LLM01:2025 Prompt Injection               | High       | Governance of AI, Risk Management of AI Systems      | Unauthorized access, data leakage      | Strict input validation, enforce prompt integrity    |
| LLM02:2025 Sensitive Information Disclosure | High       | AI Data Confidentiality, Information Governance     | Exposure of sensitive information      | Data masking, access controls                       |
| LLM03:2025 Supply Chain Vulnerabilities   | Medium     | Third-Party Management, Secure AI Integration       | Malicious components, unverified dependencies | Regular audits, use of dependency monitoring tools   |
| LLM04:2025 Data and Model Poisoning       | High       | AI Data Integrity, Model Governance                  | Compromised training data, incorrect outputs | Data audits, secure data pipelines                  |
| LLM05:2025 Insecure Output Handling       | Medium     | Output Governance, AI Content Management            | Data leakage, injection vulnerabilities | Output filtering, output format definitions         |
| LLM06:2025 Excessive Agency               | Medium     | Control and Oversight of AI Actions, Autonomous System Governance | Unintended autonomous actions          | Enforce least privilege, human approval for high-risk actions |
| LLM07:2025 System Prompt Leakage          | Medium     | Information Security Governance, AI System Security  | System prompt exposure                 | Conceal system prompts, implement secure configurations |
| LLM08:2025 Vector and Embedding Weaknesses | Medium     | Data Governance, Bias and Fairness in AI Systems    | Biased or malicious outputs            | Adversarial testing, secure vector storage          |
| LLM09:2025 Misinformation                 | Medium     | Data Accuracy and Reliability, Model Performance Governance | Inaccurate or misleading content      | Cross-verification, human oversight                  |
| LLM10:2025 Unbounded Consumption          | Low        | AI Resource Management, Risk Management of AI System Performance | Excessive resource usage, denial of service | Rate-limiting, load balancing                       |

---

## [LLM01:2025 Prompt Injection](https://genai.owasp.org/)

- **Description**: Prompt injection occurs when user inputs alter the behaviour of the LLM, potentially causing unauthorized access or manipulation.

- **ISO/IEC 38507 Mapping**:
  - **ISO/IEC 38507: 5.2 Governance of AI**: Define policies that prevent unauthorized modifications through prompt inputs.
  - **ISO/IEC 38507: 6.1 Risk Management of AI Systems**: Manage risks by validating and securing input data to prevent unauthorized access.

- **Mitigation Strategies**:
  1. Define and enforce clear boundaries for model behaviour.
  2. Validate expected output formats to control responses.

- **Key Risks**: Unauthorized access, data leakage
- **Top Mitigation Steps**: Strict input validation, enforce prompt integrity

---

## [LLM02:2025 Sensitive Information Disclosure](https://genai.owasp.org/)

- **Description**: LLMs can inadvertently expose sensitive data, such as personal information or proprietary content.

- **ISO/IEC 38507 Mapping**:
  - **ISO/IEC 38507: 5.4 AI Data Confidentiality**: Enforce data protection measures to prevent the unauthorized release of sensitive information.
  - **ISO/IEC 38507: 6.2 Information Governance**: Implement controls to maintain confidentiality and restrict access based on user roles.

- **Mitigation Strategies**:
  1. Apply data masking and sanitization.
  2. Use access controls to limit data exposure.

- **Key Risks**: Exposure of sensitive information
- **Top Mitigation Steps**: Data masking, access controls

---

## [LLM03:2025 Supply Chain Vulnerabilities](https://genai.owasp.org/)

- **Description**: Vulnerabilities in the AI supply chain can lead to security risks in LLM integrations.

- **ISO/IEC 38507 Mapping**:
  - **ISO/IEC 38507: 6.3 Third-Party Management**: Develop strategies to secure third-party components and integrations.
  - **ISO/IEC 38507: 5.5 Secure AI Integration**: Regularly assess and verify the integrity of supply chain dependencies.

- **Mitigation Strategies**:
  1. Perform regular audits of third-party components.
  2. Monitor and manage dependencies using security tools.

- **Key Risks**: Malicious components, unverified dependencies
- **Top Mitigation Steps**: Regular audits, dependency monitoring tools

---

## [LLM04:2025 Data and Model Poisoning](https://genai.owasp.org/)

- **Description**: Data poisoning occurs when malicious inputs compromise training data, leading to skewed or incorrect outputs.

- **ISO/IEC 38507 Mapping**:
  - **ISO/IEC 38507: 5.3 AI Data Integrity**: Ensure data used in AI systems is accurate and unaltered to prevent poisoning.
  - **ISO/IEC 38507: 6.4 Model Governance**: Implement model governance policies to verify training data integrity.

- **Mitigation Strategies**:
  1. Conduct regular data audits to detect anomalies.
  2. Use secure data pipelines.

- **Key Risks**: Compromised training data, incorrect outputs
- **Top Mitigation Steps**: Data audits, secure data pipelines

---

## [LLM05:2025 Insecure Output Handling](https://genai.owasp.org/)

- **Description**: LLMs may produce outputs that disclose sensitive information or perform unintended actions.

- **ISO/IEC 38507 Mapping**:
  - **ISO/IEC 38507: 6.5 Output Governance**: Manage LLM outputs to prevent data leakage or unauthorized commands.
  - **ISO/IEC 38507: 5.6 AI Content Management**: Control output formats and sanitize outputs to prevent harmful content.

- **Mitigation Strategies**:
  1. Apply output filtering and validation.
  2. Define strict output formats to manage risks.

- **Key Risks**: Data leakage, injection vulnerabilities
- **Top Mitigation Steps**: Output filtering, output format definitions

---

## [LLM06:2025 Excessive Agency](https://genai.owasp.org/)

- **Description**: Excessive agency refers to unintended autonomous actions by LLMs, such as making decisions outside of the intended scope.

- **ISO/IEC 38507 Mapping**:
  - **ISO/IEC 38507: 5.7 Control and Oversight of AI Actions**: Limit autonomous capabilities in LLMs.
  - **ISO/IEC 38507: 6.6 Autonomous System Governance**: Implement oversight mechanisms for high-risk automated actions.

- **Mitigation Strategies**:
  1. Enforce privilege control and limit autonomy.
  2. Require human approval for high-risk actions.

- **Key Risks**: Unintended autonomous actions
- **Top Mitigation Steps**: Enforce least privilege, human approval for high-risk actions

---

## [LLM07:2025 System Prompt Leakage](https://genai.owasp.org/)

- **Description**: Exposure of system prompts can enable unauthorized access to model controls.

- **ISO/IEC 38507 Mapping**:
  - **ISO/IEC 38507: 6.7 Information Security Governance**: Secure sensitive prompts and restrict access.
  - **ISO/IEC 38507: 5.8 AI System Security**: Protect configurations to prevent prompt leakage.

- **Mitigation Strategies**:
  1. Conceal system prompts and store them securely.
  2. Use secure configuration practices.

- **Key Risks**: System prompt exposure
- **Top Mitigation Steps**: Conceal system prompts, secure configurations

---

## [LLM08:2025 Vector and Embedding Weaknesses](https://genai.owasp.org/)

- **Description**: Vulnerabilities in embeddings can lead to biased or manipulated outputs.

- **ISO/IEC 38507 Mapping**:
  - **ISO/IEC 38507: 5.9 Data Governance**: Ensure data used for embeddings is validated and safe.
  - **ISO/IEC 38507: 6.8 Bias and Fairness in AI Systems**: Monitor for bias in embeddings and vectors.

- **Mitigation Strategies**:
  1. Conduct adversarial testing to assess embedding weaknesses.
  2. Use secure storage for embeddings and vectors.

- **Key Risks**: Biased or malicious outputs
- **Top Mitigation Steps**: Adversarial testing, secure vector databases

---

## [LLM09:2025 Misinformation](https://genai.owasp.org/)

- **Description**: LLMs may generate inaccurate or misleading content, affecting data quality.

- **ISO/IEC 38507 Mapping**:
  - **ISO/IEC 38507: 5.10 Data Accuracy and Reliability**: Ensure accuracy in the data used for training and outputs.
  - **ISO/IEC 38507: 6.9 Model Performance Governance**: Regularly validate model performance to prevent misinformation.

- **Mitigation Strategies**:
  1. Apply cross-verification and human oversight.
  2. Use techniques like retrieval-augmented generation to improve accuracy.

- **Key Risks**: Inaccurate or misleading content
- **Top Mitigation Steps**: Cross-verification, human oversight

---

## [LLM10:2025 Unbounded Consumption](https://genai.owasp.org/)

- **Description**: Unbounded resource usage by LLMs may lead to performance issues, including denial-of-service (DoS).

- **ISO/IEC 38507 Mapping**:
  - **ISO/IEC 38507: 5.11 AI Resource Management**: Control resource allocation to avoid overuse.
  - **ISO/IEC 38507: 6.10 Risk Management of AI System Performance**: Implement protections to prevent DoS and manage resource load.

- **Mitigation Strategies**:
  1. Apply rate-limiting and load balancing.
  2. Monitor resource consumption to prevent DoS.

- **Key Risks**: Excessive resource usage, denial of service
- **Top Mitigation Steps**: Rate-limiting, load balancing

---

This mapping integrates LLM security with ISO/IEC 38507 governance principles, supporting organizations in aligning AI use with governance and risk management frameworks.

**Next Steps**:
- Implement mitigation strategies based on the risk level of each vulnerability.
- Use tools for continuous monitoring and risk management aligned with ISO/IEC 38507.
- Stay engaged with AI governance communities to adopt evolving best practices.

**Further Reading**:
- [ISO/IEC 38507 AI Governance Standards](https://www.iso.org)
- [OWASP Top 10 for LLM Applications](https://genai.owasp.org)
